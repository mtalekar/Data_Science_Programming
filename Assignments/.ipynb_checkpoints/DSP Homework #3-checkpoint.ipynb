{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,roc_auc_score,f1_score,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inmporting the dataset and splitting data into train and test partitions\n",
    "X, y = make_moons(n_samples=500, noise=0.15, random_state=55)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ploting above created dataset\n",
    "def plot_dataset(X, y, axes):\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bs\")\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\")\n",
    "    plt.axis(axes)\n",
    "    plt.grid(True, which='both')\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=20)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=20, rotation=0)\n",
    "\n",
    "plot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building following model with linear kernal to separate data linearly, considerate c value should give better margin and accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[44  7]\n",
      " [ 8 41]]\n",
      "Accuracy Score: 0.850\n",
      "ROC_AUC Score: 0.850\n",
      "Mean Square Error: 0.150\n"
     ]
    }
   ],
   "source": [
    "C=1\n",
    "svc = svm.SVC(kernel='linear', C=C).fit(X_train, y_train)\n",
    "a = svc.predict(X_test)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test,a))\n",
    "print('Accuracy Score: %.3f' %  accuracy_score(y_test, a))\n",
    "print('ROC_AUC Score: %.3f' %  roc_auc_score(y_test, a))\n",
    "print('Mean Square Error: %.3f' %  mean_squared_error(y_test,a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building following model because polynomial kernal provides more generalized representation of the linear kernal, low c value should give larger margin for which I am interested in checking the accuracy and I am setting higher value of degree to create more flexible boundaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[41 10]\n",
      " [ 2 47]]\n",
      "Accuracy Score: 0.880\n",
      "ROC_AUC Score: 0.882\n",
      "Mean Square Error: 0.120\n"
     ]
    }
   ],
   "source": [
    "C = 0.5\n",
    "poly_svc = svm.SVC(kernel='poly', degree=5, C=C).fit(X_train, y_train)\n",
    "c = poly_svc.predict(X_test)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test,c))\n",
    "print('Accuracy Score: %.3f' %  accuracy_score(y_test, c))\n",
    "print('ROC_AUC Score: %.3f' %  roc_auc_score(y_test, c))\n",
    "print('Mean Square Error: %.3f' %  mean_squared_error(y_test, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building following model with RBF kernel where I am expecting better results as RBF has the advantage of K-NN algortihm and overcomes the space complexity problem. I am setting comparitvely higher C value to create more accurate and smaller margins and high gamma value should create more close curvatures providing accurate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[50  1]\n",
      " [ 1 48]]\n",
      "Accuracy Score: 0.980\n",
      "ROC_AUC Score: 0.980\n",
      "Mean Square Error: 0.020\n"
     ]
    }
   ],
   "source": [
    "C=1.5\n",
    "rbf_svc = svm.SVC(kernel='rbf', gamma=1, C=C).fit(X_train, y_train)\n",
    "b = rbf_svc.predict(X_test)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test,b))\n",
    "print('Accuracy Score: %.3f' %  accuracy_score(y_test, b))\n",
    "print('ROC_AUC Score: %.3f' %  roc_auc_score(y_test, b))\n",
    "print('Mean Square Error: %.3f' %  mean_squared_error(y_test,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[48  3]\n",
      " [ 3 46]]\n",
      "Accuracy Score: 0.940\n",
      "ROC_AUC Score: 0.940\n",
      "Mean Square Error: 0.060\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier(n_estimators=350, max_leaf_nodes=15, n_jobs=-1)\n",
    "rnd_clf.fit(X_train,y_train)\n",
    "r = rnd_clf.predict(X_test)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test,r))\n",
    "print('Accuracy Score: %.3f' %  accuracy_score(y_test, r))\n",
    "print('ROC_AUC Score: %.3f' %  roc_auc_score(y_test, r))\n",
    "print('Mean Square Error: %.3f' %  mean_squared_error(y_test,r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After comparing the results of Ensemble model with the SVM classifier models, I can say that the results of ensemble model are better than the Linear and the Polynomial classifier where the results are better than those. Additionally Ensemble is also better than the RBF model because it will avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset and \n",
    "housing = pd.read_csv(\"housing.csv\")\n",
    "housing.dropna(axis=0, inplace=True)\n",
    "housing_Y = housing.drop(\"ocean_proximity\", axis=1) # drop labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the prediction column\n",
    "housing_target = housing[\"ocean_proximity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "housing_Y_std = scaler.fit_transform(housing_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10216, 9), (10217, 9))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting data in 50-50 training and testing\n",
    "train_x, test_x, train_y, test_y = train_test_split(housing_Y_std, housing_target, test_size=0.5)\n",
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(15, 10, 7), max_iter=500)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating MLP classifier with three hidden layers of 15, 10 and 7 nodes with max iterations set to 500\n",
    "dnn_clf = MLPClassifier(hidden_layer_sizes=(15,10,7),\n",
    "                       max_iter=500)\n",
    "\n",
    "dnn_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking number of iterations without early stopping \n",
    "dnn_clf.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[4241   98    0   14  142]\n",
      " [ 113 3144    0    9    0]\n",
      " [   0    0    2    0    0]\n",
      " [  23    3    0 1075    8]\n",
      " [ 216    0    0   65 1064]]\n",
      "Accuracy Score: 0.932\n"
     ]
    }
   ],
   "source": [
    "#predicting and checking the confusion matrix along with accuracy score\n",
    "test_y_pred = dnn_clf.predict(test_x)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_y, test_y_pred))\n",
    "print('Accuracy Score: %.3f' %  accuracy_score(test_y, test_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP model with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(early_stopping=True, hidden_layer_sizes=(15, 10, 7), max_iter=500)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf = MLPClassifier(hidden_layer_sizes=(15,10,7),\n",
    "                       max_iter=500,early_stopping=True)\n",
    "\n",
    "dnn_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking number of iterations with early stopping \n",
    "dnn_clf.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[4036   69    0  220  170]\n",
      " [ 143 3096    0   27    0]\n",
      " [   0    0    0    0    2]\n",
      " [ 162   30    0  883   34]\n",
      " [ 325    9    0  121  890]]\n",
      "Accuracy Score: 0.872\n"
     ]
    }
   ],
   "source": [
    "#predicting and checking the confusion matrix along with accuracy score\n",
    "test_y_pred = dnn_clf.predict(test_x)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_y, test_y_pred))\n",
    "print('Accuracy Score: %.3f' %  accuracy_score(test_y, test_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on above results I can conclude that the early stopping hurt the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_target = housing[[\"ocean_proximity\"]]\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_labels_ord = ordinal_encoder.fit_transform(housing_target)\n",
    "housing_labels_ord[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting datatype to integer\n",
    "housing_labels_int = housing_labels_ord.astype(int)\n",
    "housing_labels_int.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data in 50-50 training and testing\n",
    "train_x, test_x, train_y, test_y = train_test_split(housing_Y_std, housing_labels_int, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(15, input_dim=9, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "\n",
    "#final layer: there has to be 5 nodes with softmax (because we have 5 categories)\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model\n",
    "#Optimizer:\n",
    "sgd = keras.optimizers.SGD(learning_rate=0.07)\n",
    "#You need to use \"categorical_crossentropy\" for mutli-class\n",
    "#but since our target is ordinal, we need to use \"sparse_...\"\n",
    "#if it is binary classification, then use binary_crossentropy\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 0.9182\n",
      "Epoch 2/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.9119\n",
      "Epoch 3/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.2003 - accuracy: 0.9177\n",
      "Epoch 4/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.9170\n",
      "Epoch 5/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.2032 - accuracy: 0.9159\n",
      "Epoch 6/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9139\n",
      "Epoch 7/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1985 - accuracy: 0.9189\n",
      "Epoch 8/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.2004 - accuracy: 0.9167\n",
      "Epoch 9/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.2009 - accuracy: 0.9153\n",
      "Epoch 10/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.9218\n",
      "Epoch 11/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.2108 - accuracy: 0.9134\n",
      "Epoch 12/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.2042 - accuracy: 0.9194\n",
      "Epoch 13/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1973 - accuracy: 0.9191\n",
      "Epoch 14/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.9188\n",
      "Epoch 15/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.9200\n",
      "Epoch 16/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.9200\n",
      "Epoch 17/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.9204\n",
      "Epoch 18/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.9193\n",
      "Epoch 19/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1903 - accuracy: 0.9199\n",
      "Epoch 20/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.9179\n",
      "Epoch 21/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.9205\n",
      "Epoch 22/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.9168\n",
      "Epoch 23/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.9208\n",
      "Epoch 24/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.9211\n",
      "Epoch 25/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.9183\n",
      "Epoch 26/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.9219\n",
      "Epoch 27/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1878 - accuracy: 0.9223\n",
      "Epoch 28/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.9184\n",
      "Epoch 29/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.9253\n",
      "Epoch 30/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.9237\n",
      "Epoch 31/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.9207\n",
      "Epoch 32/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9210\n",
      "Epoch 33/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.9214\n",
      "Epoch 34/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.9262\n",
      "Epoch 35/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.9212\n",
      "Epoch 36/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.9237\n",
      "Epoch 37/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.9234\n",
      "Epoch 38/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.9253\n",
      "Epoch 39/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.9190\n",
      "Epoch 40/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.9226\n",
      "Epoch 41/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.9287\n",
      "Epoch 42/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.9233\n",
      "Epoch 43/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.9203\n",
      "Epoch 44/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.9242\n",
      "Epoch 45/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.9263\n",
      "Epoch 46/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.9264\n",
      "Epoch 47/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.9251\n",
      "Epoch 48/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.9238\n",
      "Epoch 49/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.9235\n",
      "Epoch 50/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.9272\n",
      "Epoch 51/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9226\n",
      "Epoch 52/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.9205\n",
      "Epoch 53/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.9243\n",
      "Epoch 54/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.9230\n",
      "Epoch 55/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.9276\n",
      "Epoch 56/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.9242\n",
      "Epoch 57/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1782 - accuracy: 0.9257\n",
      "Epoch 58/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.9252\n",
      "Epoch 59/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.9246\n",
      "Epoch 60/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.9267\n",
      "Epoch 61/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.9248\n",
      "Epoch 62/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1772 - accuracy: 0.9246\n",
      "Epoch 63/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.9266\n",
      "Epoch 64/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1698 - accuracy: 0.9293\n",
      "Epoch 65/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.9269\n",
      "Epoch 66/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.9270\n",
      "Epoch 67/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1691 - accuracy: 0.9289\n",
      "Epoch 68/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.9288\n",
      "Epoch 69/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1692 - accuracy: 0.9296\n",
      "Epoch 70/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1778 - accuracy: 0.9271\n",
      "Epoch 71/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.9276\n",
      "Epoch 72/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1913 - accuracy: 0.9206\n",
      "Epoch 73/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1772 - accuracy: 0.9267\n",
      "Epoch 74/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.9246\n",
      "Epoch 75/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9287\n",
      "Epoch 76/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1913 - accuracy: 0.9205\n",
      "Epoch 77/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1671 - accuracy: 0.9290\n",
      "Epoch 78/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1703 - accuracy: 0.9326\n",
      "Epoch 79/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.9277\n",
      "Epoch 80/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1717 - accuracy: 0.9283\n",
      "Epoch 81/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1693 - accuracy: 0.9289\n",
      "Epoch 82/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1727 - accuracy: 0.9300\n",
      "Epoch 83/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1736 - accuracy: 0.9284\n",
      "Epoch 84/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1697 - accuracy: 0.9266\n",
      "Epoch 85/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1653 - accuracy: 0.9309\n",
      "Epoch 86/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.9324\n",
      "Epoch 87/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.9256\n",
      "Epoch 88/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.9265\n",
      "Epoch 89/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9288\n",
      "Epoch 90/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1675 - accuracy: 0.9320\n",
      "Epoch 91/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1716 - accuracy: 0.9287\n",
      "Epoch 92/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.9283\n",
      "Epoch 93/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.9250\n",
      "Epoch 94/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1636 - accuracy: 0.9297\n",
      "Epoch 95/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9349\n",
      "Epoch 96/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1778 - accuracy: 0.9283\n",
      "Epoch 97/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1668 - accuracy: 0.9286\n",
      "Epoch 98/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9322\n",
      "Epoch 99/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.9283\n",
      "Epoch 100/100\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1731 - accuracy: 0.9268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25bb8a73a90>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 953us/step - loss: 0.2451 - accuracy: 0.9049\n",
      "\n",
      "accuracy: 90.49%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(test_x, test_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on above results, I can conclude that keras model is worse compared to the MLP classifier model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
